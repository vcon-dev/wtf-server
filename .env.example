# WTF Server Configuration
# Copy this to .env and fill in your values

# Server
PORT=3000
HOST=0.0.0.0
LOG_LEVEL=info

# Default ASR Provider
# Options: nvidia, openai, deepgram, groq, local-whisper, mlx-whisper
ASR_PROVIDER=nvidia

# ============================================
# NVIDIA NIM ASR (Parakeet/Canary models)
# ============================================
NIM_ASR_URL=http://localhost:9000
# NIM_API_KEY=optional-api-key
# NIM_DEFAULT_MODEL=parakeet-tdt-1.1b
# NIM_TIMEOUT_MS=300000

# ============================================
# OpenAI Whisper API
# Get key: https://platform.openai.com/api-keys
# ============================================
# OPENAI_API_KEY=sk-your-key-here
# OPENAI_BASE_URL=https://api.openai.com/v1
# OPENAI_MODEL=whisper-1
# OPENAI_TIMEOUT_MS=300000

# ============================================
# Deepgram
# Get key: https://console.deepgram.com/
# ============================================
# DEEPGRAM_API_KEY=your-deepgram-key
# DEEPGRAM_MODEL=nova-2
# DEEPGRAM_TIMEOUT_MS=300000

# ============================================
# Groq (Fast Whisper)
# Get key: https://console.groq.com/keys
# ============================================
# GROQ_API_KEY=gsk_your-groq-key
# GROQ_MODEL=whisper-large-v3-turbo
# GROQ_TIMEOUT_MS=300000

# ============================================
# Local Whisper Server
# (faster-whisper-server, whisper.cpp, etc.)
# ============================================
# LOCAL_WHISPER_URL=http://localhost:9001
# LOCAL_WHISPER_MODEL=base
# LOCAL_WHISPER_TIMEOUT_MS=600000

# ============================================
# MLX Whisper (Apple Silicon)
# Python sidecar: pip install vcon-mac-wtf && vcon-mac-wtf
# ============================================
# MLX_WHISPER_URL=http://localhost:8000
# MLX_WHISPER_MODEL=mlx-community/whisper-turbo
# MLX_WHISPER_TIMEOUT_MS=600000

# ============================================
# Limits
# ============================================
MAX_AUDIO_SIZE_MB=100
MAX_VCON_SIZE_MB=200
